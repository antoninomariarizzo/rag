{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with PDF files and OCR\n",
    "\n",
    "This demo provides an example where retrieval is performed on PDF files.\n",
    "\n",
    "Note: To run the code with your own data, simply update the folder path (or the `folder_path` variable) accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the notebook is running on Google Colab, and if so, install the dependencies\n",
    "try:\n",
    "    # Mount Google Drive to access files and directories\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd ./drive/MyDrive/\n",
    "\n",
    "    # Clone Git repository\n",
    "    !git clone --quiet https://github.com/antoninomariarizzo/rag.git\n",
    "    %cd ./rag/\n",
    "    !python -m pip install -e .\n",
    "\n",
    "    # Install dependencies\n",
    "    !apt-get install -y tesseract-ocr\n",
    "    %pip install -r requirements.txt\n",
    "    \n",
    "    print(\"Running on Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Not running on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, whoami\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if token:\n",
    "    print(\"Token loaded successfully!\")\n",
    "else:\n",
    "    print(\"Token not found in the .env file\")\n",
    "\n",
    "login(token=token)\n",
    "\n",
    "# Check if the login was successful \n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"Logged in successfully as: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Login failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.PDFProcessor import PDFProcessor\n",
    "from src.LargeLanguageModel import LargeLanguageModel\n",
    "from src.IndexManager import IndexManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"pdf_files/\"\n",
    "index_path = 'resources/faiss_embeddings.index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PDF files from folder  \n",
    "Extract text from PDF files in the specified folder (e.g., `folder_path = \"pdf_files/\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, info = PDFProcessor.extract_text_from_pdfs_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into smaller chunks for better retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, info = IndexManager.chunk_texts_and_info(texts, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Load the Embedding Index\n",
    "\n",
    "Prepare dataset of embeddings from text for the retrieval. Build an index for efficient similarity search.\n",
    "\n",
    "Find relevant text and then use an LLM to generate a response based on this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM and IndexManager\n",
    "llm = LargeLanguageModel(model_id=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "index_manager = IndexManager(chunks, info, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(index_path):\n",
    "    print(\"Create embedding index\")\n",
    "    index = index_manager.create_index(texts,\n",
    "                                       index_path)\n",
    "else:\n",
    "    print(\"Load embedding index\")\n",
    "    index = index_manager.load_index(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieval\n",
    "\n",
    "Retrieves the top-k relevant references, and constructs a prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does this document say about attention mechanism?\"\n",
    "references = index_manager.query(text=query, top_k=5)\n",
    "\n",
    "context = \"\\n\".join([text for text, _ in references])\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.decode(prompt)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(answer)\n",
    "print(\"\\nReferences:\")\n",
    "for text_cur, info_cur in references:\n",
    "    fname, page_num = info_cur.split()\n",
    "    print(f\"- {fname}, page {page_num}: {text_cur[:20]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
