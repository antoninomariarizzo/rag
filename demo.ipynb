{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG from PDF files\n",
    "\n",
    "This demo provides an example where retrieval is performed on PDF files.\n",
    "\n",
    "Note: To run the code with your own data, simply update the folder path (or the `folder_path` variable) accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.PDFProcessor import PDFProcessor\n",
    "from src.LargeLanguageModel import LargeLanguageModel\n",
    "from src.IndexManager import IndexManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"pdf_files/\"\n",
    "index_path = 'resources/faiss_embeddings.index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PDF files from folder  \n",
    "Extract text from PDF files in the specified folder (e.g., `folder_path = \"pdf_files/\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, info = PDFProcessor.extract_text_from_pdfs_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into smaller chunks for better retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, info = IndexManager.chunk_texts_and_info(texts, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Load the Embedding Index\n",
    "\n",
    "Prepare dataset of embeddings from text for the retrieval. Build an index for efficient similarity search.\n",
    "\n",
    "Find relevant text and then use an LLM to generate a response based on this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM and IndexManager\n",
    "llm = LargeLanguageModel(model_id=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "index_manager = IndexManager(chunks, info, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(index_path):\n",
    "    print(\"Create embedding index\")\n",
    "    index = index_manager.create_index(texts,\n",
    "                                       index_path)\n",
    "else:\n",
    "    print(\"Load embedding index\")\n",
    "    index = index_manager.load_index(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrieval\n",
    "\n",
    "Retrieves the top-k relevant references, and constructs a prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does this document say about attention mechanism?\"\n",
    "references = index_manager.query(text=query, top_k=5)\n",
    "\n",
    "context = \"\\n\".join([text for text, _ in references])\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.decode(prompt)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(answer)\n",
    "print(\"\\nReferences:\")\n",
    "for text_cur, info_cur in references:\n",
    "    fname, page_num = info_cur.split()\n",
    "    print(f\"- {fname}, page {page_num}: {text_cur[:20]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
